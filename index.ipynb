{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression in Statsmodels\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lecture, you'll learn how to run your first multiple linear regression model.\n",
    "\n",
    "## Objectives\n",
    "You will be able to:\n",
    "* Use statsmodels to fit a multiple linear regression model\n",
    "* Evaluate a linear regression model by using statistical performance metrics pertaining to overall model and specific parameters\n",
    "\n",
    "## Statsmodels for multiple linear regression\n",
    "\n",
    "This lesson will be more of a code-along, where you'll walk through a multiple linear regression model using both statsmodels and scikit-learn. \n",
    "\n",
    "Recall the initial regression model presented. It determines a line of best fit by minimizing the sum of squares of the errors between the models predictions and the actual data. In algebra and statistics classes, this is often limited to the simple 2 variable case of $y=mx+b$, but this process can be generalized to use multiple predictive variables.\n",
    "\n",
    "## Auto-mpg data\n",
    "\n",
    "The code below reiterates the steps you've seen before: \n",
    "* Creating dummy variables for each categorical feature\n",
    "* Log-transforming select continuous predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('auto-mpg.csv') \n",
    "data['horsepower'].astype(str).astype(int)\n",
    "\n",
    "acc = data['acceleration']\n",
    "logdisp = np.log(data['displacement'])\n",
    "loghorse = np.log(data['horsepower'])\n",
    "logweight= np.log(data['weight'])\n",
    "\n",
    "scaled_acc = (acc-min(acc))/(max(acc)-min(acc))\t\n",
    "scaled_disp = (logdisp-np.mean(logdisp))/np.sqrt(np.var(logdisp))\n",
    "scaled_horse = (loghorse-np.mean(loghorse))/(max(loghorse)-min(loghorse))\n",
    "scaled_weight= (logweight-np.mean(logweight))/np.sqrt(np.var(logweight))\n",
    "\n",
    "data_fin = pd.DataFrame([])\n",
    "data_fin['acc'] = scaled_acc\n",
    "data_fin['disp'] = scaled_disp\n",
    "data_fin['horse'] = scaled_horse\n",
    "data_fin['weight'] = scaled_weight\n",
    "cyl_dummies = pd.get_dummies(data['cylinders'], prefix='cyl', drop_first=True)\n",
    "yr_dummies = pd.get_dummies(data['model year'], prefix='yr', drop_first=True)\n",
    "orig_dummies = pd.get_dummies(data['origin'], prefix='orig', drop_first=True)\n",
    "mpg = data['mpg']\n",
    "data_fin = pd.concat([mpg, data_fin, cyl_dummies, yr_dummies, orig_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 392 entries, 0 to 391\n",
      "Data columns (total 23 columns):\n",
      "mpg       392 non-null float64\n",
      "acc       392 non-null float64\n",
      "disp      392 non-null float64\n",
      "horse     392 non-null float64\n",
      "weight    392 non-null float64\n",
      "cyl_4     392 non-null uint8\n",
      "cyl_5     392 non-null uint8\n",
      "cyl_6     392 non-null uint8\n",
      "cyl_8     392 non-null uint8\n",
      "yr_71     392 non-null uint8\n",
      "yr_72     392 non-null uint8\n",
      "yr_73     392 non-null uint8\n",
      "yr_74     392 non-null uint8\n",
      "yr_75     392 non-null uint8\n",
      "yr_76     392 non-null uint8\n",
      "yr_77     392 non-null uint8\n",
      "yr_78     392 non-null uint8\n",
      "yr_79     392 non-null uint8\n",
      "yr_80     392 non-null uint8\n",
      "yr_81     392 non-null uint8\n",
      "yr_82     392 non-null uint8\n",
      "orig_2    392 non-null uint8\n",
      "orig_3    392 non-null uint8\n",
      "dtypes: float64(5), uint8(18)\n",
      "memory usage: 22.3 KB\n"
     ]
    }
   ],
   "source": [
    "data_fin.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, let's simplify the model and only inlude `'acc'`, `'horse'` and the three `'orig'` categories in our final data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>weight</th>\n",
       "      <th>orig_2</th>\n",
       "      <th>orig_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.720986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.908047</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.651205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.648095</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.148810</td>\n",
       "      <td>0.664652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  acceleration    weight  orig_2  orig_3\n",
       "0  18.0      0.238095  0.720986       0       0\n",
       "1  15.0      0.208333  0.908047       0       0\n",
       "2  18.0      0.178571  0.651205       0       0\n",
       "3  16.0      0.238095  0.648095       0       0\n",
       "4  17.0      0.148810  0.664652       0       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ols = pd.concat([mpg, scaled_acc, scaled_weight, orig_dummies], axis=1)\n",
    "data_ols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A linear model using statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use the `statsmodels.api` to run OLS on all of the data. Just like for linear regression with a single predictor, you can use the formula $y \\sim X$ with $n$ predictors where $X$ is represented as $x_1+\\ldots+x_n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'mpg ~ acceleration+weight+orig_2+orig_3'\n",
    "model = ols(formula=formula, data=data_ols).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having to type out all the predictors isn't practical when you have many. Another better way than to type them all out is to seperate out the outcome variable `'mpg'` out of your DataFrame, and use the a `'+'.join()` command on the predictors, as done below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'mpg'\n",
    "predictors = data_ols.drop('mpg', axis=1)\n",
    "pred_sum = '+'.join(predictors.columns)\n",
    "formula = outcome + '~' + pred_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.726</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.723</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   256.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 18 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>1.86e-107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:36:57</td>     <th>  Log-Likelihood:    </th> <td> -1107.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2224.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   387</td>      <th>  BIC:               </th> <td>   2244.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   20.7608</td> <td>    0.688</td> <td>   30.181</td> <td> 0.000</td> <td>   19.408</td> <td>   22.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration</th> <td>    5.0494</td> <td>    1.389</td> <td>    3.634</td> <td> 0.000</td> <td>    2.318</td> <td>    7.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>       <td>   -5.8764</td> <td>    0.282</td> <td>  -20.831</td> <td> 0.000</td> <td>   -6.431</td> <td>   -5.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_2</th>       <td>    0.4124</td> <td>    0.639</td> <td>    0.645</td> <td> 0.519</td> <td>   -0.844</td> <td>    1.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_3</th>       <td>    1.7218</td> <td>    0.653</td> <td>    2.638</td> <td> 0.009</td> <td>    0.438</td> <td>    3.005</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>37.427</td> <th>  Durbin-Watson:     </th> <td>   0.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  55.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.648</td> <th>  Prob(JB):          </th> <td>6.95e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.322</td> <th>  Cond. No.          </th> <td>    8.47</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.726\n",
       "Model:                            OLS   Adj. R-squared:                  0.723\n",
       "Method:                 Least Squares   F-statistic:                     256.7\n",
       "Date:                Wed, 18 Mar 2020   Prob (F-statistic):          1.86e-107\n",
       "Time:                        21:36:57   Log-Likelihood:                -1107.2\n",
       "No. Observations:                 392   AIC:                             2224.\n",
       "Df Residuals:                     387   BIC:                             2244.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       20.7608      0.688     30.181      0.000      19.408      22.113\n",
       "acceleration     5.0494      1.389      3.634      0.000       2.318       7.781\n",
       "weight          -5.8764      0.282    -20.831      0.000      -6.431      -5.322\n",
       "orig_2           0.4124      0.639      0.645      0.519      -0.844       1.669\n",
       "orig_3           1.7218      0.653      2.638      0.009       0.438       3.005\n",
       "==============================================================================\n",
       "Omnibus:                       37.427   Durbin-Watson:                   0.840\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               55.989\n",
       "Skew:                           0.648   Prob(JB):                     6.95e-13\n",
       "Kurtosis:                       4.322   Cond. No.                         8.47\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols(formula=formula, data=data_ols).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or even easier, simply use the `ols()` function from `statsmodels.api`. The advantage is that you don't have to create the summation string. Important to note, however, is that the intercept term is not included by default, so you have to make sure you manipulate your `predictors` DataFrame so it includes a constant term. You can do this using `.add_constant`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.726</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.723</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   256.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 26 Sep 2019</td> <th>  Prob (F-statistic):</th> <td>1.86e-107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:01:03</td>     <th>  Log-Likelihood:    </th> <td> -1107.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2224.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   387</td>      <th>  BIC:               </th> <td>   2244.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>   20.7608</td> <td>    0.688</td> <td>   30.181</td> <td> 0.000</td> <td>   19.408</td> <td>   22.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration</th> <td>    5.0494</td> <td>    1.389</td> <td>    3.634</td> <td> 0.000</td> <td>    2.318</td> <td>    7.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>       <td>   -5.8764</td> <td>    0.282</td> <td>  -20.831</td> <td> 0.000</td> <td>   -6.431</td> <td>   -5.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_2</th>       <td>    0.4124</td> <td>    0.639</td> <td>    0.645</td> <td> 0.519</td> <td>   -0.844</td> <td>    1.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_3</th>       <td>    1.7218</td> <td>    0.653</td> <td>    2.638</td> <td> 0.009</td> <td>    0.438</td> <td>    3.005</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>37.427</td> <th>  Durbin-Watson:     </th> <td>   0.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  55.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.648</td> <th>  Prob(JB):          </th> <td>6.95e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.322</td> <th>  Cond. No.          </th> <td>    8.47</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.726\n",
       "Model:                            OLS   Adj. R-squared:                  0.723\n",
       "Method:                 Least Squares   F-statistic:                     256.7\n",
       "Date:                Thu, 26 Sep 2019   Prob (F-statistic):          1.86e-107\n",
       "Time:                        12:01:03   Log-Likelihood:                -1107.2\n",
       "No. Observations:                 392   AIC:                             2224.\n",
       "Df Residuals:                     387   BIC:                             2244.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const           20.7608      0.688     30.181      0.000      19.408      22.113\n",
       "acceleration     5.0494      1.389      3.634      0.000       2.318       7.781\n",
       "weight          -5.8764      0.282    -20.831      0.000      -6.431      -5.322\n",
       "orig_2           0.4124      0.639      0.645      0.519      -0.844       1.669\n",
       "orig_3           1.7218      0.653      2.638      0.009       0.438       3.005\n",
       "==============================================================================\n",
       "Omnibus:                       37.427   Durbin-Watson:                   0.840\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               55.989\n",
       "Skew:                           0.648   Prob(JB):                     6.95e-13\n",
       "Kurtosis:                       4.322   Cond. No.                         8.47\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "predictors_int = sm.add_constant(predictors)\n",
    "model = sm.OLS(data['mpg'],predictors_int).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>weight</th>\n",
       "      <th>orig_2</th>\n",
       "      <th>orig_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mpg</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.423329</td>\n",
       "      <td>-0.844194</td>\n",
       "      <td>0.244313</td>\n",
       "      <td>0.451454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>acceleration</td>\n",
       "      <td>0.423329</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.401563</td>\n",
       "      <td>0.208298</td>\n",
       "      <td>0.115020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>weight</td>\n",
       "      <td>-0.844194</td>\n",
       "      <td>-0.401563</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.295206</td>\n",
       "      <td>-0.471220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>orig_2</td>\n",
       "      <td>0.244313</td>\n",
       "      <td>0.208298</td>\n",
       "      <td>-0.295206</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.230157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>orig_3</td>\n",
       "      <td>0.451454</td>\n",
       "      <td>0.115020</td>\n",
       "      <td>-0.471220</td>\n",
       "      <td>-0.230157</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mpg  acceleration    weight    orig_2    orig_3\n",
       "mpg           1.000000      0.423329 -0.844194  0.244313  0.451454\n",
       "acceleration  0.423329      1.000000 -0.401563  0.208298  0.115020\n",
       "weight       -0.844194     -0.401563  1.000000 -0.295206 -0.471220\n",
       "orig_2        0.244313      0.208298 -0.295206  1.000000 -0.230157\n",
       "orig_3        0.451454      0.115020 -0.471220 -0.230157  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ols.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAADxCAYAAAAz6fmnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAU60lEQVR4nO3dfbBdVXnH8e+PEBKUAIkJkCHBgKUMCDWpd8AZZipGXiJqdKa+JI4aOzgZGG2xvkFGRyjKTKwzQjttKSlEolIQUWvqS2kEouMI0URjIERMQGoh0QgBwQYScu/TP/Y+d06u9569Ts665+3+PjN77jn79bkheVhr77XXo4jAzKyRwzodgJl1PycKM6vkRGFmlZwozKySE4WZVXKiMLNKThRmXUjSakm7JT04xnZJ+kdJOyRtkfTndduWSdpeLstyxONEYdadbgEWNdj+BuDUclkO3AAgaQZwFXAOcDZwlaTprQbjRGHWhSLiB8CeBru8BfhiFO4HjpU0G7gIWBcReyLiaWAdjRNOEicKs950IvC/dd8fL9eNtb4lh7d6AjODi1730nhqz2DSvpu27NsKvFC3alVErGrykhplXTRY3xInCrMMntwzyIa75iTtO3n2Iy9ExECLl3wcmFv3fQ6ws1x/3oj161u8lrseZnkEgzGUtGSyFnhv+fTjNcDvI2IXcBdwoaTp5U3MC8t1LXGLwiyDAIZab+EPk3QbRctgpqTHKZ5kTAaIiH8FvgNcDOwA9gJ/VW7bI+nTwE/KU10TEY1uiiZxojDLIAhejLR7FEnni1hasT2AD4yxbTWwOlswOFGYZZOzRdFtuvIehaRFkh4uR51d2eFYGo6Qa3MscyXdK2mbpK2SLu9wPFMl/VjSz8t4/q6T8dRImiTpZ5K+1a5rBjBIJC29qOsShaRJwD9TjDw7A1gq6YwOhnQLGQasZHIA+EhEnA68BvhAh/9s9gELI+JVwHxgUXljrdMuB7a1+6JDRNLSi7ouUVAMO90REY9GxH7gdopRaB2RMEKubSJiV0T8tPz8HMU/hpYH07QQT0TEH8qvk8ulo/8SJM0B3gjc1M7rBjAYkbT0om5MFOMysqzfSJoHLAA2dDiOSZI2A7sphg53NB7geuDjQLbnkKmGEpde1I2JYlxGlvUTSUcBXwM+FBHPdjKWiBiMiPkUA3vOlnRmp2KR9CZgd0Rsave1I/H+RK/eo+jGpx5jjTgzQNJkiiRxa0R8vdPx1ETEM5LWU9zP6dSN33OBxZIuBqYCR0v6ckS8e7wvHAEv9mYOSNKNLYqfAKdKOlnSEcASilFoE54kATcD2yLi810QzyxJx5afjwTOB37RqXgiYkVEzImIeRR/b+5pR5IoiMHEpRd1XaKIiAPABymGnW4D7oiIrZ2Kpxwhdx9wmqTHJV3SqVgo/o/5HmChpM3lcnEH45kN3CtpC0WCXxcRbXsk2U0CGIq0pRfJBYDMWnfmnx0Rd3x7VtK+rzxp56YML4W1VTfeozDrOcWAq97sVqRwojDLZCicKMysAbcozKxSIF6MSZ0OY9x03VOPGknLOx1DPcfTWDfF04lYai0KPx5tv675i1dyPI11UzwdiEUMxmFJSy9y18Msg2KGq95MAinGJVHMnDEp5s2d3NI5TjrxcAZeNTXLII+Hnz+25XNMOW4a0/70hCzxaPv+ls8xlZdwtGa0HM++k49sORaASTOPYcopJ7Ycz5TJB1qOZerx0zj6tONbjuWF3zzL/t8/n9xX6NVuRYpxSRTz5k7mx3fNrd6xTc578K2dDuEgUy58rNMhDHvk2gWdDuEgrzjhd50OYdiGS/89ed8I9Wy3IoW7HmaZDLlFYWaNBGJ/9O8/p/5tK5m1Ue1mZsqSomreWEnX1b0Y+EtJz9RtG6zbluXN6/5NgWZtNphpCHfdvLEXUMzP8hNJayPiodo+EfG3dfv/NcVsZzXPl5MJZeMWhVkGgRjksKQlQbPzxi4Fbsvwa4zJicIsk6E4LGlJkDxvrKSXAycD99Stnippo6T7JWV55Oeuh1kGxRDu5P/vzpS0se77yGrmzcwbuwS4M+KgMmUnRcROSacA90h6ICIeSQ1uNE4UZhk0+VLYkxUT1zQzb+wSRpQWjIid5c9Hy3lMFwAtJQp3PcwyiCDnux5J88ZKOg2YTjFVY23ddElTys8zKaZPfGjksc1yi8IsC2UbcBURByTV5o2dBKyOiK2SrgE2RkQtaSwFbo+D57M8HbhR0hBFQ2Bl/dOSQ+VEYZZBUSksXwM9Ir4DfGfEuk+N+H71KMf9CDgrWyAlJwqzTJq4mdlzkn6zbqoubtaNAjEUaUsvqmxRpIwSM7P+blGkdD2GR4kBSKqNEnOiMCv1+5yZKYlitFFi54xPOGa9qagUNrFbFEmjxMoJTZdDMTuV2UTTzzNcpaTApFFiEbEqIgYiYmDWy/q3CWY2mgjlfNej66T8r394lBjwBMUosXeNa1RmPWhCT4U31iixcY/MrIcUE9f0b9cj6WbCaKPEzKyeJ9c1swoBE/7xqJlVqI3M7FdOFGaZuFKYmTVUzEfhFoWZVXDXw8waKu5RuOthZhX6eQi3E4VZBoE4MOTHo2ZWYcKPzDSzxvzUw8yS+GammTXkkZmH4OHnj+W8B7OUPMxi/Zn/0ekQDvLaNy/vdAjDhl4crN6pjbZvG7XEZkfse+GIpvbPeY9C0iLgHyje2L4pIlaO2P4+4HMUUz8A/FNE3FRuWwZ8slz/mYhY02o8blGYZVBMhZcnUTQxofVXIuKDI46dAVwFDJRhbSqPfbqVmPq3U2XWTlE8Hk1ZEgxPaB0R+4HahNYpLgLWRcSeMjmsAxYd0u9Ux4nCLIPaxDUpC2U187plZF90tAmtR+uT/aWkLZLulFSbrjL12Ka462GWSRNdj6pq5ikTWv8ncFtE7JN0KbAGWJh4bNPcojDLoHaPIlOlsMoJrSPiqYjYV379N+DVqcceCicKs0wyJorhCa0lHUExofXa+h0kza77uhjYVn6+C7hQ0nRJ04ELy3UtcdfDLIOc4yjGmtBa0jXAxohYC/yNpMXAAWAP8L7y2D2SPk2RbACuiYg9rcbkRGGWQ8CBjCMzR5vQOiI+Vfd5BbBijGNXA6uzBYMThVkWOcdRdCMnCrNMnCjMrCG/62FmScKJwsyqeOIaM2soor/vUVQ+z5G0WtJuSQ+2IyCz3iQGhw5LWnpRStS3kOHtM7N+F6GkpRdVdj0i4geS5o1/KGa9y+MoEpWvyi4HmHLctFynNesNUdyn6FfZOkwRsSoiBiJiYPIxL8l1WrOe0cR8FD3HTz3MMgg8jsLMKvX3yMyUx6O3AfcBp0l6XNIl4x+WWe8ZGlLS0otSnnosbUcgZr0swl0PM0vQz10PJwqzTPr58agThVkm7nqYWUNB7w7PTuFEYZZJH/c8nCjMsgiIHn30maI333k160I53x6VtEjSw5J2SLpylO0flvRQWVLwbkkvr9s2KGlzuawdeeyhcIvCLJNcTz0Sq5n/DBiIiL2SLgP+Hnhnue35iJifJ5qCWxRmGdTe9cjUoqisZh4R90bE3vLr/RSlA8eNE4VZDgGE0pZ81cxrLgG+W/d9anne+yW9Ncev566HWSZNdD1yVDMvdpTeDQwAr61bfVJE7JR0CnCPpAci4pHk6EbhFoVZLpG4VEuqSC7pfOATwOK6yuZExM7y56PAemBBs7/KSOPSotD2/Uy58LHxOPUhee2bR7bsOuv7N67qdAjDzrnisk6HcJCjntjf6RCGPfV0M3cnlfPx6HA1c+AJimrm7zroatIC4EZgUUTsrls/HdgbEfskzQTOpbjR2RJ3PcxyyPj2aGI1888BRwFflQTw64hYDJwO3ChpiKLHsHLE05JD4kRhlkvGoZkJ1czPH+O4HwFn5Yuk4ERhlk3/jsx0ojDLpY9f9nCiMMvFicLMGurzl8KcKMxycYvCzCp54hozqyK3KMysofTh2T3JicIsC7nrYWYJ3KIws0pDnQ5g/DhRmOVQm7imT6UUKZ4r6V5J2yRtlXR5OwIz6zWKtKUXpbQoDgAfiYifSpoGbJK0Lserq2Z9pUeTQIrKFkVE7IqIn5afnwO20Xj+PjPrM03do5A0j2JarQ2jbFsOLAeYyksyhGbWW3q1W5EiOVFIOgr4GvChiHh25PaIWAWsAjhaM/r4j8xsDH18MzMpUUiaTJEkbo2Ir49vSGY9KJjYj0dVTMh3M7AtIj4//iGZ9aZ+7nqkTNd/LvAeYGFdPcOLxzkus96Tb7r+rlPZooiIH9LPkwGa5dKjSSCFCwCZZZA62Cq1e5JQzXyKpK+U2zeUTyRr21aU6x+WdFGO38+JwiyX9NqjDdVVM38DcAawVNIZI3a7BHg6Iv4EuA74bHnsGRQFg14JLAL+pTxfS5wozHLJd4+ispp5+X1N+flO4PXlg4e3ALdHxL6I+BWwozxfS5wozDLRUNqSIKWa+fA+EXEA+D3wssRjm+a3R81yaO6Fr5mSNtZ9X1UOWKxJqWY+1j7JldCb4URhlkv6P8cnI2KgwfaUaua1fR6XdDhwDLAn8dimuethlku+exTD1cwlHUFxc3LtiH3WAsvKz28D7omIKNcvKZ+KnAycCvy4hd8KcIvCLJtcIzMTq5nfDHxJ0g6KlsSS8titku4AHqKYIuIDETHYakxOFGZdKKGa+QvA28c49lrg2pzxOFGY5dLHIzOdKMxyiORHnz1pXBLFvpOP5JFrF4zHqQ/J0Istd9GyOueKyzodwrANn72h0yEc5NVXd8+fzeDPm3zFyS0KM2tE9Pdr5k4UZrk4UZhZQz08FX8KJwqzXJwozKyKn3qYWTW3KMysoR6eDzOFE4VZJr6ZaWbVnCjMrIpbFGZWzYnCzBppZir+XuREYZaLE4WZVXGLwsyqTeREIWkq8ANgSrn/nRFx1XgHZtZzJnKiAPYBCyPiD5ImAz+U9N2IuH+cYzPrHRP9ZmY5Bfgfyq+Ty6WP/0jMDlEf/6tIqushaZKkzcBuYF1EbBhln+WSNkraOPjc/+WO06zrZSwp2Pg60gxJ6yRtL39OH2Wf+ZLuk7RV0hZJ76zbdoukX0naXC7zq66ZlCgiYjAi5lNUHTpb0pmj7LMqIgYiYmDStJemnNasr9TGUlQtGVwJ3B0RpwJ3l99H2gu8NyJqVc2vl3Rs3faPRcT8ctlcdcGmKoVFxDPA+vLCZlaTWiUsT6Kor2S+BnjrH4UT8cuI2F5+3knRG5h1qBesTBSSZtUykaQjgfOBXxzqBc36VvsSxfERsQug/Hlco50lnQ0cATxSt/rasktynaQpVRdMeeoxG1gjaRJFYrkjIr6VcJzZhNHkLNxV1cyR9D3ghFGO/URTcUmzgS8ByyKidodkBfAbiuSxCrgCuKbReVKeemwBuqdIh1m3ylfNnIg4f6xtkn4raXZE7CoTwe4x9jsa+DbwyfrhDLXWCLBP0heAj1YF7GrmZpkoImnJoL6S+TLgm38US1EF/RvAFyPiqyO2zS5/iuL+xoNVF3SiMMsh2vd4FFgJXCBpO3BB+R1JA5JuKvd5B/AXwPtGeQx6q6QHgAeAmcBnqi7odz3McmnTgKuIeAp4/SjrNwLvLz9/GfjyGMcvbPaaThRmmUzoIdxmlsiJwswamugvhZlZIicKM2ukyQFXPceJwiwTDfVvpnCiMMvBJQXNLIWrmTdpyuQDvOKE343HqQ/J9m0ndjqEgxz1xP5OhzDs1Vdf1ukQDrLp6hs6HcKws+9r8u+wWxRmVsU3M82ssQDyvPDVlZwozDLxPQoza8jjKMysWoS7HmZWzS0KM6vmRGFmVdyiMLPGAvC7HmZWxY9Hzayan3qYWRXfozCzxvr8NXPX9TDLoBiZ2Z4CQJJmSFonaXv5c/oY+w3W1fRYW7f+ZEkbyuO/UhYLaig5UUiaJOlnklx31Gw0Q4lL664E7o6IU4G7y++jeT4i5pfL4rr1nwWuK49/Grik6oLNtCguB7Y1sb/ZhNLGkoJvAdaUn9dQlAVMi7EoI7gQuLOZ45MShaQ5wBuBm6r2NZuQIopxFClLWc28blne5NWOrxUaLn8eN8Z+U8vz3y+plgxeBjwTEQfK748DlTM7pd7MvB74ODAtcX+zCaeJpx6V1cwlfQ84YZRNn2gipJMiYqekU4B7ynqjz46yX2XklYlC0puA3RGxSdJ5DfZbDiwHmHq884lNQBnHUUTE+WNtk/RbSbMjYldZmXz3GOfYWf58VNJ6YAHwNeBYSYeXrYo5wM6qeFK6HucCiyU9BtwOLJT0R8VPI2JVRAxExMDkY45MOK1ZH2lvNfO1wLLy8zLgmyN3kDRd0pTy80yKf8cPRUQA9wJva3T8SJWJIiJWRMSciJgHLAHuiYh3V/8uZhNMbU6KqqV1K4ELJG0HLii/I2lAUu0+4unARkk/p0gMKyPioXLbFcCHJe2guGdxc9UFPeDKLJc2DbiKiKeA14+yfiPw/vLzj4Czxjj+UeDsZq7ZVKKIiPXA+maOMZsoMj367EpuUZjlEMCgE4WZNSCyDabqSk4UZrk4UZhZJScKM2soyPXCV1dyojDLxPcozKyaE4WZNRQBQ/3b93CiMMulf/OEE4VZLr5HYWbVnCjMrCFXCmvec7/c/eT3Fl7/Py2eZibwZI54MskWT6t/MKU88dzdeiClLPFMujFDJPn+W708fddsr5B3pXFJFBExq9VzSNpYNV1YOzmexropno7F4kRhZg0FMNi/jz2cKMyyCAgnik5Y1ekARnA8jXVTPJ2JxV2P9ouIbvqL53gqdFM8HYnFTz3MLIlbFGZWqY8ThauZm+UQAYODaUuLUqqZS3pdXSXzzZJeqJUVlHSLpF/VbZtfdU0nCrNc2lfXo7KaeUTcW6tkTlGUeC/w33W7fKyu0vnmqgs6UZjl0r5E0Ww187cB342IvYd6QScKsyy6spp5zRLgthHrrpW0RdJ1tdKDjfhmplkOAZE+4Kpd1cwpixifBdxVt3oF8BvgCIoxJ1cA1zQ6jxOFWS4Zx1HkqGZeegfwjYh4se7cu8qP+yR9AfhoVTzuepjl0r57FJXVzOssZUS3o0wuSBLF/Y0Hqy7oFoVZDrXHo+2xErhD0iXAr4G3Q1HNHLg0It5ffp8HzAW+P+L4WyXNAgRsBi6tuqAThVkm0abJdVOqmZffHwNOHGW/hc1e04nCLAtPXGNmVfxSmJkl8XwUZtZIAOEWhZk1FJ7hyswSRPsej7adoo/v1Jq1i6T/oigTkOLJiFg0nvHk5kRhZpU8hNvMKjlRmFklJwozq+REYWaVnCjMrNL/A0nbumYoCgRNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(data_ols.corr())\n",
    "cb = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "Just like for single multiple regression, the coefficients for the model should be interpreted as \"how does $y$ change for each additional unit $X$\"? However, do note that since $X$ was transformed, the interpretation can sometimes require a little more attention. In fact, as the model is built on the transformed $X$, the actual relationship is \"how does $y$ change for each additional unit $X'$\", where $X'$ is the (log- and min-max, standardized,...) transformed data matrix.\n",
    "\n",
    "## Linear regression using scikit-learn\n",
    "\n",
    "You can also repeat this process using scikit-learn. The code to do this can be found below. The scikit-learn package is known for its machine learning functionalities and generally very popular when it comes to building a clear data science workflow. It is also commonly used by data scientists for regression. The disadvantage of scikit-learn compared to statsmodels is that it doesn't have some statistical metrics like the p-values of the parameter estimates readily available. For a more *ad-hoc* comparison of scikit-learn and statsmodels, you can read this blogpost: https://blog.thedataincubator.com/2017/11/scikit-learn-vs-statsmodels/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data_ols['mpg']\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(predictors, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.04941007, -5.87640551,  0.41237454,  1.72184708])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coefficients\n",
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intercept of the model is stored in the `.intercept_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.760757080821836"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intercept\n",
    "linreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congrats! You now know how to build a linear regression model with multiple predictors in statsmodel and scikit-learn. You also took a look at the statistical performance metrics pertaining to the overall model and its parameters!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
